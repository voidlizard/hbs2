FIXME: filter-existed-objects-from-log
  Сейчас если коммит ссылается на уже существующие в стейте
  объекты, они всё попадут в лог. Нужно отфильтровывать их
  оттуда

TODO: faster-git-clone
  Медленное клонирование.
  Можно попытаться оптимизировать, можно
  попытаться сделать через fast-import -- т.е
  дампить объекты в формате fast-import-stream,
  должно быть намного быстрее

FIXME: faster-export
  Сейчас обходятся вообще все коммиты в git rev-list,
  а можно только те, которых нет в стейте - т.е начиная
  с какого-то. Ну например, для данной ссылке брать коммит
  с максимальной высотой (глубиной) и rev-list делать до него.
  Пример:
  ```
      [dmz@minipig:~/w/hbs2]$ git rev-list --objects 640c447e9dca6a32ecb80f85f2d3ab9ad45dc91e..
    0e887a87e30005a8ebdb43aa5bf0ed78383cf52a
    5509c970621a75c9f82b4d2743fd211c1165e61f
    7f0c4c0659367ae10bd3eb84b7bc26f09dd26282 hbs2-git
    6d38123f72101aa6a66c35ced40f5dd156a722c4 hbs2-git/lib
    1aadc3441288d6d4f9fddb00342dd296242ded1a hbs2-git/lib/HBS2Git
    bb270a54495fdf44e831b53c63b5814a44d354af hbs2-git/lib/HBS2Git/State.hs
  ```

TODO: git-tags-support
  Поддержать теги, в т.ч. подписанные.
  Неподписанные возможно  и так будут работать.

TODO: log-object-reorder-for-better-dedup
 Вот что еще заметил: сейчас пишу в логи операции в порядке:
 (коммит, зависимости). Поскольку так удачно сложилось, что гит
 новые коммиты делает не дельтами, а все объекты целиком пишет,
 то что бы там разработчик не мутил - сквошил, мержил, ребейзил
 - итоговые блобы и деревья (снапшот проекта) — выглядят
 довольно константными.  таким образом, если сначала в лог
 писать деревья и блобы, а в конец - коммиты,  то есть шансы,
 что префикс лога будет более константным, что ли. т.е при
 последующем разбиении на сегменты есть шансы, что сегменты в
 начале лога будут лучше дедупиться.

TODO: hbs2-git-log-segmentation
  Нарезать логи на сегменты  с фиксированным числом
  коммитов, что бы:
    1. Сегменты были вменяемого размера
    2. Лучше бы работала дедупликация
    3. При эскспорте больших репо можно было бы отправлять
       сегменты до полной обработки репозитория так,
       что бы к концу экспорта большая часть данных
       уже была в hbs2.

